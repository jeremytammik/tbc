<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="bc.css">
<!-- https://highlightjs.org/#usage
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
<script>hljs.highlightAll();</script>
-->

<!-- https://prismjs.com -->
<link href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css" rel="stylesheet" />
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/components/prism-core.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>
<style> code[class*=language-], pre[class*=language-] { font-size : 90%; } </style>
</head>

<!---

- revisiting q4r4 with llm and rag
  Breaking up is hard to do: Chunking in RAG applications
  https://stackoverflow.blog/2024/06/06/breaking-up-is-hard-to-do-chunking-in-rag-applications/

- graphrag -- https://youtu.be/r09tJfON6kE

- claude.ai helped chunk tbc blog posts
  i asked claude.ai to chunk The Building Coder blog posts for LLM RAG with the following series of five prompts:
  how would you suggest chunking this markdown-formatted blog post, splitting it up into separate documents delineated by the #### h4 section headers?
  that sounds good. how would you handle the same task automatically for 2046 blog posts?
  could you suggest how to code this in Python, please?
  actually, please improve the script as follows: split the input MD files into chunks using all headers as separators, and store the output in JSON files. each JSON should contain the following fields: original filename, header text, local header href, and chunk text.
  the script you provided misses many of the section headers, because they have a href html tag directly joined to the markup header hash characters, like this: ####<a name=\"2\"></a> Personalised Material Asset Properties
  it generated 696 json files, one for each blog posts from number 1351 to today's number 2046.
  i was writing them in html until number 1350, so i'll need to implement a different script to chunk those.
  the result looks perfect.
  with just five short prompts.
  i corrected nothing whatsoever, didn't even look at the code generated.
  all i did was type in the input and output folder paths.
  i am pretty impressed.
  i went on to ask for a similar script to process earlier html-formatted blog posts, using the following prompts;
  that worked very well, and the result looks good. i also have a collection of older blog posts that i wrote in html instead of markdown. could you please write a similar script to chunk up the html blog posts in a similar way to the same json format?
  that script worked fine for a few of the files, but then it produced the following error: UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 4049: invalid continuation byte
  i'm afraid that made things worse. now it produces an error in the very first file, saying: File "/Users/jta/a/src/python/tbcchunk/tbcchunk3.py", line 34, in chunk_html: `for elem in soup.body.children`: AttributeError: 'NoneType' object has no attribute 'children'
  after that all was well, all 2046 blog posts processed and chunked
  /Users/jta/a/src/python/tbcchunk/

twitter:

 with the @AutodeskRevit #RevitAPI #BIM @DynamoBIM

&ndash; ...

linkedin:

#BIM #DynamoBIM #AutodeskAPS #Revit #API #IFC #SDK #Autodesk #AEC #adsk

the [Revit API discussion forum](http://forums.autodesk.com/t5/revit-api-forum/bd-p/160) thread

<center>
<img src="img/" alt="" title="" width="600"/>
<p style="font-size: 80%; font-style:italic"></p>
</center>

-->

### Q4R4 Chunk

####<a name="2"></a>

**Question:**

**Answer:**

<pre><code class="language-sh">ug+ -i searchtext *pdf</code></pre>

<center>
<img src="img/.jpg" alt="" title="" width="100"/>
</center>

